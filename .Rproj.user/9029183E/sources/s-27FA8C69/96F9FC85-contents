# Sentiment analysis of ePad student responses

rm(list=ls())


library(tm)
# library(plyr)
library(qdap)

# read transcript
dat1 <- read.transcript(file.choose())

# abbreviations
my_abv <- c("bb", "vle", "T&L", "exp ", "uni ", "pg", "p/t", "fb", "it's", "I'm")
my_rep <- c("Blackboard", "Virtual Learning Environment", "teaching and learning", 
            "experience ", "university ", "postgraduate", "part-time", "FaceBook",
            "it is", "I am")
my_abbs <- data.frame(my_abv, my_rep)
colnames(my_abbs) <- c("abv","rep")
Key <- rbind(abbreviations, my_abbs)

# words to keep together
keeps <- c("Virtual Learning Environment", "teaching and learning")


# split by person
interviewer <- split(dat1, dat1$person)[['ME']]
interviewee <- split(dat1, dat1$person!='ME')[['TRUE']]

interviewee$dialogue <- replace_abbreviation(interviewee$dialogue, Key)
interviewee$dialogue <- replace_contraction(interviewee$dialogue) 

interviewee$dialogue <- space_fill(interviewee$dialogue, keeps)
interviewee$dialogue <- strip(interviewee$dialogue, lower=F)

interviewee$dialogue <- rm_stopwords(interviewee$dialogue, Top200Words)

interviewee_words <- bag_o_words(interviewee$dialogue, lower=F)





#wfm(interviewee_words)
#out <- ngrams(interviewee$dialogue)
#pull out interviewee words
#client_words <- all_words(interviewee)




# look at adjacent words

# not ready yet

doc.corpus <- tm_map(doc.corpus, content_transformer(removePunctuation)) # remove punctuation
doc.corpus <- tm_map(doc.corpus, content_transformer(removeNumbers))
tm_words <- tm_map(mat_interviewee, content_transformer(tolower))

amatrix <- adjacency_matrix(client_words$WORD)

#sort
client_words <- client_words[order(-client_words$FREQ),]   


#remove common words
dat2 <- rm_stopwords(client_words$WORD, tm::stopwords("english"))  #remove common words

                   
                      
                      
                      
bing_lex <- get_sentiments("bing")
nrc_lex <- get_sentiments("nrc")
afinn_lex <- get_sentiments("afinn")



td_new <- data.frame(colSums(preppedsentiment))
td_new <- cbind("sentiment" = rownames(td_new), td_new)
numobs <- paste("(n = ",length(prepped),")", sep="")

op <- par(no.readonly=T)
par(mar=c(5.1,6,4.1,2.1))
c_range <- c('firebrick', 'plum1', 'yellow4', 'yellow', 'orchid', 'orange', ' hotpink', 'blue','green','red')

barplot(td_new[,2], 
  horiz=T, 
  main="How well did you feel prepared for using ePAD?", 
  xlab="Sentiment identified using nrc lexicon", 
  sub = numobs,
  col = c_range, 
  #legend.text = td_new[,1],
  names.arg=td_new[,1], las=1
)

#===============================================


par(op)
